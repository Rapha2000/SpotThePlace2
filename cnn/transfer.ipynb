{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Datasets and Dataloaders"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "from torch.utils.data import Dataset, Subset, DataLoader\n",
    "import os\n",
    "from PIL import Image\n",
    "import os\n",
    "import random\n",
    "\n",
    "class CustomImageDataset(Dataset):\n",
    "    def __init__(self, image_dir, transform=None, num_images_per_country=200):\n",
    "        self.image_dir = image_dir\n",
    "        self.transform = transform\n",
    "        self.num_images_per_country = num_images_per_country\n",
    "        \n",
    "        # Liste des sous-dossiers (chaque sous-dossier correspond à un pays)\n",
    "        self.country_dirs = [d for d in os.listdir(image_dir) if os.path.isdir(os.path.join(image_dir, d))]\n",
    "\n",
    "        self.image_files = []\n",
    "        self.labels = []\n",
    "        \n",
    "        # Récupérer les images et labels\n",
    "        for idx, country in enumerate(self.country_dirs):\n",
    "            country_path = os.path.join(image_dir, country)\n",
    "            \n",
    "            # Liste des fichiers d'images pour ce pays\n",
    "            country_images = [f for f in os.listdir(country_path) if f.endswith('.png')]\n",
    "\n",
    "            # Limiter le nombre d'images récupérées par pays, si spécifié\n",
    "            if self.num_images_per_country:\n",
    "                country_images = random.sample(country_images, min(self.num_images_per_country, len(country_images)))\n",
    "            \n",
    "            for img_name in country_images:\n",
    "                self.image_files.append(os.path.join(country_path, img_name))\n",
    "                self.labels.append(country)  # Le label est le nom du pays (le sous-dossier)\n",
    "\n",
    "        # Encodage des labels (pays -> indices)\n",
    "        self.label_encoder = LabelEncoder()\n",
    "        self.labels = self.label_encoder.fit_transform(self.labels)\n",
    "        \n",
    "        # Stocker les noms de classes pour référence future\n",
    "        self.class_names = self.label_encoder.classes_\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.image_files)\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        # Charger l'image\n",
    "        img_name = self.image_files[idx]\n",
    "        image = Image.open(img_name).convert('RGB')\n",
    "        \n",
    "        # Appliquer les transformations (si fournies)\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        \n",
    "        # Récupérer le label associé\n",
    "        label = self.labels[idx]\n",
    "        \n",
    "        return image, label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train set size: 320\n",
      "Validation set size: 40\n",
      "Test set size: 40\n"
     ]
    }
   ],
   "source": [
    "from torchvision import transforms\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "# Transformations pour les images (redimensionnement et normalisation)\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),  # ResNet attend des images 224x224\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])  # Normalisation standard\n",
    "])\n",
    "\n",
    "# Instantiate the dataset\n",
    "image_dir = '../script/streetview_scrapping/images'  # Dossier contenant les sous-dossiers des pays\n",
    "dataset = CustomImageDataset(image_dir=image_dir, transform=transform)\n",
    "\n",
    "# Split dataset into training, validation and test sets\n",
    "train_size = int(0.8 * len(dataset))\n",
    "validation_size = (len(dataset) - train_size) // 2\n",
    "test_size = len(dataset) - train_size - validation_size\n",
    "\n",
    "trainset, valset, testset = random_split(dataset, [train_size, validation_size, test_size])\n",
    "\n",
    "# Create DataLoaders\n",
    "trainloader = DataLoader(trainset, batch_size=4, shuffle=True)\n",
    "valloader = DataLoader(valset, batch_size=4, shuffle=True)\n",
    "testloader = DataLoader(testset, batch_size=4, shuffle=True)\n",
    "\n",
    "# Check class distribution\n",
    "print(f\"Train set size: {len(trainset)}\")\n",
    "print(f\"Validation set size: {len(valset)}\")\n",
    "print(f\"Test set size: {len(testset)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer Learning (Feature Extraction)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torchvision.models import resnet18, ResNet18_Weights\n",
    "from torchvision import models\n",
    "\n",
    "# Load a pre-trained ResNet-18 model\n",
    "model = models.resnet18(weights=ResNet18_Weights.IMAGENET1K_V1)\n",
    "\n",
    "# Modify the final fully connected layer to match the number of classes\n",
    "num_classes = len(dataset.class_names)\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "\n",
    "# Move the model to the GPU if available\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model = model.to(device)\n",
    "\n",
    "# Define the loss function and optimizer\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
    "\n",
    "def train_model(model, trainloader, valloader, criterion, optimizer, num_epochs=25):\n",
    "    best_model_wts = model.state_dict()\n",
    "    best_acc = 0.0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print(f'Epoch {epoch}/{num_epochs - 1}')\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Chaque époque a une phase d'entraînement et de validation\n",
    "        for phase in ['train', 'val']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Met le modèle en mode entraînement\n",
    "                dataloader = trainloader\n",
    "            else:\n",
    "                model.eval()   # Met le modèle en mode évaluation\n",
    "                dataloader = valloader\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Boucle sur les données\n",
    "            for inputs, labels in dataloader:\n",
    "                inputs = inputs.to(device)\n",
    "                labels = labels.to(device)\n",
    "\n",
    "                # Remise à zéro des gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # Passage avant et arrière\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # Propagation arrière + optimisation si on est en phase d'entraînement\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "            epoch_loss = running_loss / len(dataloader.dataset)\n",
    "            epoch_acc = running_corrects.double() / len(dataloader.dataset)\n",
    "\n",
    "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
    "\n",
    "            if phase == 'val' and epoch_acc > best_acc:\n",
    "                best_acc = epoch_acc\n",
    "                best_model_wts = model.state_dict()\n",
    "\n",
    "        print()\n",
    "\n",
    "    print('Best val Acc: {:.4f}'.format(best_acc))\n",
    "\n",
    "    # Charger les poids du meilleur modèle\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 0/0\n",
      "----------\n",
      "train Loss: 0.5897 Acc: 0.7643\n",
      "val Loss: 0.2939 Acc: 0.8611\n",
      "\n",
      "Best val Acc: 0.8611\n"
     ]
    }
   ],
   "source": [
    "model = train_model(model, trainloader, valloader, criterion, optimizer, num_epochs=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.8630\n"
     ]
    }
   ],
   "source": [
    "def evaluate_model(model, testloader):\n",
    "    model.eval()  # Mise en mode évaluation\n",
    "    running_corrects = 0\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in testloader:\n",
    "            inputs = inputs.to(device)\n",
    "            labels = labels.to(device)\n",
    "\n",
    "            outputs = model(inputs)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            running_corrects += torch.sum(preds == labels.data)\n",
    "\n",
    "    accuracy = running_corrects.double() / len(testloader.dataset)\n",
    "    print(f'Test Accuracy: {accuracy:.4f}')\n",
    "\n",
    "# Évaluer le modèle sur le test set\n",
    "evaluate_model(model, testloader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transfer Learning (Fine Tuning)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env-projet-dl-312",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
